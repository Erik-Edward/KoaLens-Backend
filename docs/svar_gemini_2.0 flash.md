# **Bästa praxis och alternativa metoder för pålitlig extrahering av strukturerad JSON-data från LLM för ingrediensanalys**

**1\. Introduktion:**

Den ökande användningen av stora språkmodeller (LLM) för dataextrahering och klassificering från ostrukturerade källor, såsom OCR-tolkade ingredienslistor, erbjuder möjligheter till automatisering och effektivisering. Att uppnå tillförlitlig strukturerad utdata, särskilt i format som JSON, kvarstår dock som en betydande utmaning.1 Den aktuella användarprocessen innefattar OCR av ingredienslistor från livsmedel, följt av vegansk statusklassificering med hjälp av en LLM, med målet att returnera resultaten som ett JSON-objekt. De huvudsakliga problemen som uppstår är inkonsekvent eller ogiltig JSON-utdata och felaktig klassificering av ingredienser \[User Query\].

Frekventa fall av att LLM returnerar svar med text blandad med JSON-objektet, eller felaktigt formaterad JSON, har tvingat användaren att förlita sig på en mindre robust reservlösning med regex-parsning \[User Query\]. Dessutom förekommer felklassificeringar av ingredienser, vilket indikerar begränsningar i LLM:s domänspecifika kunskap eller förmåga att följa specifika klassificeringsregler \[User Query\]. Denna rapport syftar till att tillhandahålla en detaljerad analys av bästa praxis och alternativa metoder för att hantera dessa problem, med fokus på tillförlitlig JSON-extrahering och noggrann vegansk statusklassificering med hjälp av Gemini API eller liknande LLM. De följande avsnitten kommer att behandla promptkonstruktion för tillförlitlig JSON, justering av API-parametrar, användning av funktionsanrop/verktygsanvändning, strategier för att förbättra klassificeringsnoggrannheten, alternativa arbetsflödesdesigner och robusta metoder för felhantering.

Användningen av regex-parsning som en reservlösning antyder en grundläggande instabilitet i den primära metoden för JSON-extrahering. Denna instabilitet beror sannolikt på LLM:s generativa natur, som är optimerad för naturligt språk snarare än strikta dataformat.1 Eftersom LLM tränas på stora mängder textdata, där JSON ofta är inbäddat i naturligt språk, kan modellen utan precisa instruktioner ha svårt att konsekvent avgränsa eller formatera JSON enligt strikta krav. Behovet av regex indikerar att JSON-utdata ofta är blandad med eller omgiven av annan text, vilket gör direkt parsning otillförlitlig.

Felklassificeringen av "Arom" pekar på en potentiell diskrepans mellan LLM:s allmänna kunskap och användarens interna databas eller specifika klassificeringsregler. Detta antyder att enbart förlita sig på LLM:s förtränade kunskap kanske inte är tillräckligt för noggrann domänspecifik klassificering.4 LLM tränas på omfattande datamängder men kanske inte har detaljerad eller specifik information om varje ingredienss veganska status, särskilt för tvetydiga eller allmänt benämnda ingredienser som "Arom". Detta understryker behovet av en mekanism för att vägleda LLM med mer specifik och auktoritativ information.

**2\. Strategier för att säkerställa tillförlitlig JSON-utdata:**

* **2.1. Avancerad promptkonstruktion för JSON:**  
  * **Tydliga och explicita instruktioner:** Prompten bör tydligt ange kravet på JSON-utdata och dess avsedda användning, till exempel parsning i ett specifikt programmeringsspråk.1 Att inkludera instruktioner som "Returnera utdata som ett giltigt JSON-objekt som kan parsas av Pythons json.loads()" kan vägleda modellen.  
  * **Definiera JSON-schemat i prompten:** Prompten bör tydligt definiera strukturen för den förväntade JSON-utdatan, inklusive namn och datatyper för alla nycklar (t.ex. ingredienser som en array av objekt med namn som sträng, vegansk\_status som sträng, anledning som sträng, overall\_vegansk\_status som sträng och konfidensnivå som nummer).1 Att använda en välformaterad schemadefinition i prompten fungerar som en ritning för LLM:s utdata.  
  * **Few-shot prompting med JSON-exempel:** Att tillhandahålla exempel på korrekt formaterad JSON-utdata för ingredienslistor och deras veganska status kan avsevärt förbättra modellens förmåga att följa den önskade strukturen.1 Dessa exempel visar det förväntade formatet och innehållet, vilket gör att LLM kan lära sig det önskade utdatamönstret.  
  * **Systemmeddelanden:** Att använda systemmeddelandet för att förstärka kravet på JSON-utdata och ge kontext om uppgiften kan vara fördelaktigt.1 Ett systemmeddelande som "Du är expert på att analysera livsmedelsingredienslistor och klassificera deras veganska status. Din utdata måste vara ett giltigt JSON-objekt som följer schemat som anges i användarmeddelandet" skapar rätt kontext.  
  * **Förifyllning av svaret:** Att inleda assistentens svar med den inledande delen av JSON-strukturen (t.ex. {"ingredienser": \[) kan uppmuntra modellen att slutföra strukturen i det förväntade formatet.1 Detta "lägger ord i LLM:s mun" och styr dess genereringsprocess.  
  * **Avgränsare och formatering:** Att använda tydliga avgränsare (t.ex. \<output\>...\</output\>) runt den förväntade JSON-utdatan i prompten kan hjälpa modellen att identifiera det specifika innehållet som ska formateras som JSON och kan också underlätta extrahering efter bearbetning.1  
    Även om dessa promptkonstruktionstekniker syftar till att förbättra JSON-tillförlitligheten, kan deras effektivitet variera beroende på LLM:s kapacitet och komplexiteten i det önskade schemat. Vissa LLM kan kräva mer explicita instruktioner eller starkare begränsningar.2 Olika LLM-arkitekturer och träningsdatauppsättningar kan leda till varierande nivåer av följsamhet till formateringsinstruktioner. Mer sofistikerade modeller kan följa komplexa instruktioner mer exakt, medan enklare modeller kan ha svårt med invecklade JSON-strukturer.  
    Att kombinera flera promptkonstruktionstekniker, som att tillhandahålla ett schema, exempel och tydliga instruktioner i både användar- och systemmeddelanden, kommer sannolikt att ge bättre resultat än att förlita sig på en enda teknik.1 En mångfacetterad strategi ger redundans och förstärker det önskade utdataformatet från olika vinklar, vilket ökar sannolikheten för att LLM kommer att förstå och följa instruktionerna korrekt.  
* **2.2. Utnyttja Gemini API-parametrar:**  
  * **response\_mime\_type='application/json':** Genom att ställa in den här parametern i Gemini API-konfigurationen signaleras explicit att det förväntade svaret ska vara i JSON-format.16 Även om det inte garanterar perfekt JSON eller schemaföljsamhet, uppmuntrar det modellen att formatera sin utdata i enlighet därmed.  
  * **temperature:** Att sänka parametern temperature (närmare 0\) minskar slumpmässigheten i modellens tokenval, vilket gör utdatan mer deterministisk och förutsägbar. Detta är i allmänhet fördelaktigt för strukturerad dataextrahering där konsekvens är avgörande.25 En lägre temperatur ökar sannolikheten för att modellen håller sig till det mest sannolika och konsekventa utdataformatet.  
  * **top\_p och top\_k:** Dessa parametrar styr mångfalden i den genererade texten. Att sänka deras värden kan också bidra till mer deterministiska och mindre varierade utdata, vilket kan förbättra JSON-konsekvensen.25 Genom att begränsa poolen av potentiella nästa tokens är modellen mer benägen att producera förutsägbara strukturer.  
  * **response\_schema:** Nyare Gemini-modeller (1.5 och senare) tillåter att ett schemaobjekt skickas direkt via parametern response\_schema i konfigurationen. Detta är den rekommenderade metoden för att säkerställa strikt följsamhet till en definierad JSON-struktur.20 Denna funktion tvingar fram utdataformatet på API-nivå, vilket ger en mer tillförlitlig garanti för strukturerad JSON.  
    Att använda parametern response\_schema i Gemini API, om den är tillgänglig för den modell som används, erbjuder ett betydligt mer robust tillvägagångssätt för att säkerställa att JSON-utdata följer ett fördefinierat schema jämfört med att enbart förlita sig på promptkonstruktion eller response\_mime\_type.20 response\_schema fungerar som en direkt begränsning av modellens utdataformat, som verkställs av själva API:et. Detta minskar modellens flexibilitet att avvika från den angivna strukturen, vilket leder till mer tillförlitlig och förutsägbar JSON.  
    Att justera temperature, top\_p och top\_k mot lägre värden kan komplettera promptkonstruktion och användningen av response\_schema genom att göra modellens genereringsprocess mer deterministisk, vilket minskar risken för oväntade formateringsvariationer i JSON-utdatan.25 Dessa parametrar påverkar slumpmässigheten i tokenvalet. Genom att göra valet mer förutsägbart minskar vi sannolikheten för att modellen introducerar främmande tecken eller avviker från den avsedda JSON-strukturen på grund av slumpmässiga variationer i dess utdata.

**3\. Strukturerad dataextrahering med funktionsanrop/verktygsanvändning:**

* Gemini API (och andra avancerade LLM-API:er) erbjuder funktioner för "funktionsanrop" eller "verktygsanvändning", vilket kan vara ett mer tillförlitligt sätt att extrahera strukturerad data som ingrediensinformation.9 Denna funktion gör det möjligt att definiera funktioner med specifika parametrar (namn, typ, beskrivning) som LLM kan "anropa" baserat på användarens inmatning.  
* Processen innefattar:  
  1. **Definiera funktionsdeklarationer:** Du definierar strukturen för den data du vill extrahera som en funktion med parametrar. För ingrediensanalysen kan detta innebära en funktion som analysera\_ingredienser med parametrar som ingredienslista (sträng), och LLM skulle returnera argument för denna funktion i ett strukturerat JSON-format (t.ex. en lista med ingredienser med deras veganska status och anledningar, plus produktens övergripande status och konfidensnivå).30  
  2. **Anropa modellen med funktionsdeklarationer:** Du skickar användarens prompt (den OCR-tolkade ingredienslistan) tillsammans med funktionsdeklarationen till Gemini API.30  
  3. **Utföra funktionskod (ditt ansvar):** LLM utför inte själva funktionen. Istället returnerar den ett JSON-objekt med funktionsnamnet och de argument som den anser bör användas. Din applikation extraherar sedan dessa argument.30  
  4. **Skapa ett användarvänligt svar:** Eventuellt kan du sedan använda den extraherade informationen för att utföra ytterligare åtgärder eller generera ett slutligt svar till användaren.30  
* Exempel på en potentiell funktionsdeklaration (som en Python-ordbok för Gemini API):  
  Python  
  function\_declaration \= {  
      "name": "analyze\_ingredients",  
      "description": "Analyserar en lista med ingredienser för att fastställa deras veganska status och produktens övergripande veganska status.",  
      "parameters": {  
          "type": "object",  
          "properties": {  
              "ingredient\_list": {  
                  "type": "string",  
                  "description": "Den fullständiga listan med ingredienser som extraherats från livsmedelsprodukten."  
              }  
          },  
          "required": \["ingredient\_list"\]  
      }  
  }

  LLM:s svar skulle sedan innehålla ett function\_call-objekt med de argument som ska användas med denna funktion, formaterade som JSON. Du skulle sedan bearbeta dessa argument för att extrahera den strukturerade ingrediensdatan. För mer komplex strukturerad utdata kan funktionsdeklarationens parametrar utformas för att direkt återspegla det önskade JSON-schemat (t.ex. returnera en lista med ingrediensobjekt).  
* Fördelar med funktionsanrop för detta användningsfall:  
  * **Garanterad strukturerad utdata:** Funktionsanrop är utformat för att returnera data i en fördefinierad struktur, vilket avsevärt minskar risken för felaktig eller inkonsekvent JSON.3  
  * **Tydlig schemadefinition:** Funktionsdeklarationen definierar explicit den förväntade datastrukturen, vilket gör det lättare för både LLM och din applikation att förstå och arbeta med utdatan.8  
  * **Minskad parseringskomplexitet:** Din applikation tar emot den extraherade datan som ett strukturerat objekt, vilket eliminerar behovet av komplex parsning av naturligt språk.9  
    Funktionsanrop erbjuder en mer tillförlitlig mekanism för att erhålla strukturerad data eftersom LLM är specifikt tränad för att identifiera och mata ut argument som överensstämmer med den definierade funktionssignaturen. Detta är ett mer direkt tillvägagångssätt än att instruera modellen att generera JSON i ett visst format.38 Istället för att bara förutsäga nästa token baserat på en prompt som begär JSON, uppmanar funktionsanrop LLM att identifiera och strukturera information på ett sätt som direkt motsvarar parametrarna i en definierad funktion. Denna begränsning leder till mer förutsägbar och användbar strukturerad utdata.  
    Även om funktionsanrop lägger till ett abstraktionslager genom att kräva definitionen av funktionsdeklarationer, förenklar det i slutändan processen att integrera LLM:s utdata i din applikationslogik, eftersom datan redan är strukturerad och redo att användas.37 Den initiala ansträngningen att definiera funktionsschemat lönar sig i form av minskad komplexitet vid hantering av LLM:s svar. Den strukturerade utdatan från funktionsanrop kan användas direkt för att fylla i datastrukturer eller utlösa ytterligare åtgärder i din applikation utan behov av omfattande parsning och validering av fritext.

**4\. Förbättra noggrannheten i vegansk statusklassificering:**

* **4.1. Promptkonstruktion för förbättrad klassificering:**  
  * **Tydliga och specifika instruktioner:** Prompten bör explicit instruera LLM att klassificera varje ingrediens i den angivna listan som antingen "vegansk", "icke-vegansk" eller "osäker". Tydliga definitioner för varje kategori bör tillhandahållas.48 Till exempel: "Klassificera varje ingrediens som 'vegansk' om den härrör från växter och inte innehåller några animaliska produkter, 'icke-vegansk' om den innehåller några animaliska ingredienser och 'osäker' om statusen inte kan fastställas med säkerhet."  
  * **Rollbaserad promptkonstruktion:** Att instruera LLM att anta rollen som en "expert på vegansk mat" eller "näringsexpert specialiserad på vegansk kost" kan utnyttja dess träningsdata mer effektivt och potentiellt förbättra noggrannheten.49 Detta hjälper modellen att komma åt och prioritera relevant kunskap.  
  * **Kedja-av-tankeprocess i prompten:** Att uppmuntra LLM att förklara sitt resonemang för varje klassificeringssteg kan hjälpa till att identifiera potentiella fel och förbättra den övergripande noggrannheten.5 Att till exempel be modellen att "Ge en kort förklaring till varför varje ingrediens klassificeras som vegansk, icke-vegansk eller osäker" kan göra resonemanget transparent.  
  * **Kontextuell information:** Om det är möjligt inom tokenbegränsningarna kan det vara bra att ge viss övergripande kontext om vanliga veganska och icke-veganska ingredienser för att vägleda LLM.  
  * **Few-shot prompting med klassificeringsexempel:** Att inkludera exempel på ingrediensnamn och deras korrekta veganska klassificeringar (baserat på din interna kunskap) i prompten kan fungera som en stark vägledning för LLM.51 Dessa exempel visar det förväntade klassificeringsresultatet för specifika ingredienser.  
    Även om promptkonstruktion kan påverka klassificeringsnoggrannheten, innebär LLM:s inneboende kunskapsbegränsningar och potential för "hallucinationer" att enbart förlita sig på prompter kanske inte garanterar perfekt noggrannhet, särskilt för tvetydiga eller mindre vanliga ingredienser.4 LLM genererar text baserat på mönster i sin träningsdata. Om en ingrediens inte är välrepresenterad eller om dess veganska status är kontextberoende, kan modellen göra felaktiga klassificeringar baserat på allmän kunskap eller antaganden.  
    Att kombinera olika promptkonstruktionstekniker, som tydliga instruktioner, rollspel och tillhandahållande av exempel, kan skapa en mer robust prompt som bättre vägleder LLM mot noggranna klassificeringar.48 Varje teknik adresserar en annan aspekt av att vägleda LLM. Tydliga instruktioner definierar uppgiften, rollspel fokuserar modellens kunskap och exempel ger konkreta fall av önskad utdata. Att använda dem tillsammans kan skapa en mer omfattande och effektiv prompt.  
* **4.2. Integrering av interna ingrediensdatabaser:**  
  * **Fördelar:** Att direkt införliva information från dina interna ingrediensdatabaser (listor över veganska, icke-veganska och osäkra ingredienser) i promptkontexten kan avsevärt förbättra klassificeringsnoggrannheten genom att förse LLM med auktoritativ information.58 Detta säkerställer att LLM använder dina verifierade data snarare än att enbart förlita sig på sin potentiellt ofullständiga eller felaktiga allmänna kunskap.  
  * **Nackdelar:**  
    * **Tokenbegränsningar:** Att inkludera stora databaser kan snabbt överskrida LLM:s tokenbegränsningar, särskilt för långa ingredienslistor.3  
    * **Kontextfönsterstorlek:** Ett mycket stort kontextfönster, även om det ligger inom tokenbegränsningarna, kan potentiellt späda ut den relevanta informationen och påverka prestandan.3  
    * **Promptkomplexitet:** Att hantera och inkludera databasinformation i prompter kan öka deras komplexitet.  
  * **Strategier för integrering:**  
    * **Tillhandahålla relevanta delmängder:** Istället för hela databasen, inkludera endast listorna över icke-veganska och osäkra ingredienser i prompten \[User Query\]. Detta kan hjälpa till att hantera det specifika felklassificeringsproblemet med "Arom".  
    * **Exempelbaserat tillvägagångssätt:** Använd few-shot prompting där exemplen inkluderar ingredienser och deras korrekta veganska status enligt din databas.1  
    * **Hämtningsförstärkt generering (RAG):** Implementera ett RAG-system där LLM kan fråga din interna databas (lagrad i en vektordatabas) för att hämta relevant information om varje ingrediens innan den klassificeras.5 Detta tillvägagångssätt undviker att direkt bädda in hela databasen i prompten och gör det möjligt för LLM att komma åt specifik information vid behov.

Även om direkt inkludering av databasinformation i prompten kan öka noggrannheten, kräver de praktiska begränsningarna av token- och kontextfönsterstorlekar effektivare metoder som att tillhandahålla riktade delmängder eller använda ett RAG-tillvägagångssätt.60 LLM har en begränsad kapacitet för hur mycket text de kan bearbeta åt gången. Att inkludera en stor databas direkt i prompten kan överskrida dessa gränser, vilket leder till fel eller trunkering. RAG erbjuder ett sätt att förse LLM med relevant information från databasen på begäran, utan att överbelasta kontextfönstret.För det specifika problemet med att "Arom" felklassificeras kan ett riktat tillvägagångssätt att inkludera en lista över "osäkra" ingredienser (inklusive "Arom") i promptkontexten, tillsammans med instruktioner om hur de ska hanteras, vara en enkel och effektiv lösning utan overheaden av en fullständig databasintegration \[User Query\]. Eftersom användaren specifikt nämnde "Arom" kan direkt hantering av detta i prompten genom att tillhandahålla en lista över ingredienser som bör klassificeras som "osäkra" åsidosätta LLM:s standardklassificering och säkerställa att den överensstämmer med användarens interna kunskap.

**5\. Alternativa arbetsflödesdesigner för robusthet:**

* **5.1. Tvåstegsmetod (separat OCR och klassificering):**  
  * **Steg 1: Dedikerad OCR-extrahering:** Använd LLM (eller en specialiserad OCR-motor för potentiellt bättre prestanda) för att extrahera råtexten från ingredienslistan från bilden eller videobilden. Prompten för detta steg skulle enbart fokusera på noggrann textutvinning.71  
  * **Steg 2: Separat vegansk statusklassificering:** Ta den extraherade texten och använd ett efterföljande LLM-anrop specifikt för klassificering. Prompten för detta steg skulle inkludera ingredienslistan och detaljerade instruktioner om vegansk statusklassificering, potentiellt med integrering av din interna databasinformation enligt diskussionen i avsnitt 4.2. Alternativt, för ännu högre tillförlitlighet och kontroll, kan detta steg implementeras med hjälp av regelbaserad logik och direkt uppslagning i dina interna databaser.71  
  * **Steg 3: JSON-formatering:** När den veganska statusen för varje ingrediens har fastställts, formatera resultaten i den önskade JSON-strukturen.  
  * **Fördelar:**  
    * **Förenklade prompter:** Varje LLM-anrop har ett mer fokuserat mål, vilket potentiellt leder till bättre prestanda i varje enskild uppgift.76  
    * **Ökad kontroll över klassificering:** Att separera klassificeringssteget möjliggör mer riktad promptkonstruktion eller användning av deterministisk regelbaserad logik för högre noggrannhet.76  
    * **Potentiellt bättre resurshantering:** Att dela upp uppgiften kan möjliggöra effektivare användning av LLM:s kontextfönster i varje steg.  
  * **Nackdelar:**  
    * **Ökad latens:** En tvåstegsprocess kommer sannolikt att introducera mer latens jämfört med en enstegsmetod.  
    * **Potentiell förlust av multimodal kontext:** Om du använder en multimodal LLM för en enstegsprocess kan separering av OCR leda till att vissa potentiella fördelar med att modellen förstår både texten och bildkontexten går förlorade.72

Att separera arbetsflödet i distinkta OCR- och klassificeringssteg möjliggör optimering av varje steg. Att använda ett specialiserat verktyg eller en fokuserad prompt för OCR kan säkerställa textutvinning av hög kvalitet, medan en separat, välkonstruerad prompt (eventuellt med databasintegration) eller ett regelbaserat system kan hantera klassificering med större noggrannhet.71 OCR drar nytta av modeller som är specifikt tränade på visuell-till-text-konvertering, medan klassificering kräver domänspecifik kunskap och följsamhet till definierade regler.Beslutet att anta en tvåstegsmetod innebär en avvägning mellan potentiella vinster i noggrannhet och tillförlitlighet (särskilt vid klassificering) och den ökade komplexiteten och latensen i en flerstegspipeline. Applikationens specifika behov bör styra detta beslut.77 Om noggrannhet och konsekvent följsamhet till interna klassificeringsregler är av största vikt kan en tvåstegsmetod med en robust klassificeringsmekanism (potentiellt regelbaserad) vara att föredra, även om det introducerar viss ytterligare latens. Om hastighet är en kritisk faktor kan en väloptimerad enstegsmetod vara att föredra, med en potentiellt högre risk för klassificeringsfel eller inkonsekvent JSON.

**6\. Robust felhantering för LLM-svar:**

* **6.1. Strategier för parsning på klientsidan:**  
  * **try-except-block för JSON-parsning:** Implementera robust felhantering med hjälp av try-except-block för att fånga json.JSONDecodeError när du försöker parsa LLM:s svar. Detta förhindrar att applikationen kraschar på grund av ogiltig JSON.1  
  * **Fallback med reguljära uttryck (Regex) (med förbättringar):** Förfina dina regex-mönster för att vara mer specifika för det förväntade JSON-schemat. Detta kan förbättra tillförlitligheten i fallback-mekanismen i fall där JSON är felaktigt formaterad men följer ett förutsägbart mönster.1  
  * **Identifiera JSON-gränser:** Innan parsning, använd strängmanipulering för att hitta första förekomsten av { och sista förekomsten av } i LLM:s svar. Extrahera innehållet mellan dessa avgränsare och försök att parsa endast den understrängen som JSON. Detta kan hjälpa om LLM inkluderar främmande text före eller efter JSON-objektet.1  
  * **Använda bibliotek för att reparera ogiltig JSON:** Utnyttja Python-bibliotek som json-repair för att automatiskt åtgärda vanliga JSON-fel som saknade kommatecken, citattecken eller klammerparenteser.1 Dessa bibliotek använder heuristik för att försöka korrigera felaktigt formaterade JSON-strängar.  
  * **LLM-självkorrigering:** Om parsning misslyckas, överväg att skicka tillbaka det råa LLM-svaret till modellen med en prompt som ber den att identifiera och korrigera eventuella fel i JSON-formatet och returnera giltig JSON.1  
  * **Schema-validering (efter parsning):** Efter att ha parsat JSON framgångsrikt, validera det mot ditt definierade schema med hjälp av bibliotek som Pydantic eller Cerberus. Detta säkerställer att den parsade JSON inte bara är syntaktiskt korrekt utan också innehåller de förväntade fälten med rätt datatyper.9  
  * **Hantering av partiella svar:** Kontrollera finish\_reason i Gemini API-svaret. Om det indikerar ett partiellt svar (t.ex. på grund av tokenbegränsningar), implementera logik för att hantera detta, till exempel genom att försöka begäran igen eller informera användaren om potentiell ofullständighet.9  
  * **Loggning och övervakning:** Implementera omfattande loggning för att registrera fall av parseringsfel, valideringsfel och arten av den felaktigt formaterade JSON. Dessa data kan vara ovärderliga för att identifiera återkommande problem och förfina dina prompter eller felhanteringsstrategier.83  
    En robust strategi för felhantering bör omfatta en kombination av tekniker, som inleds med grundläggande parsning och validering, fortsätter med reparationsmekanismer och eventuellt involverar LLM själv för självkorrigering. Detta skiktade tillvägagångssätt ökar pipelinens motståndskraft mot inkonsekvenser i LLM-utdata.1 Inget enskilt felhanteringsmetod är idiotsäkert. Genom att implementera en sekvens av kontroller och reparationsförsök maximerar vi chanserna att framgångsrikt extrahera den önskade strukturerade datan även när det initiala LLM-svaret inte är perfekt formaterat.  
    Även om regex kan vara en snabb initial lösning, kan ett tungt beroende av det för komplexa JSON-strukturer vara bräckligt och felbenäget. Att använda dedikerade JSON-parsning- och reparationsbibliotek erbjuder ett mer robust och underhållsbart tillvägagångssätt för att hantera felaktig JSON från LLM.1 Regex-mönster kan bli komplexa och svåra att underhålla vid hantering av nästlade JSON-strukturer eller variationer i formatering. Bibliotek som är specifikt utformade för JSON-hantering är bättre rustade för att hantera dessa komplexiteter och tillhandahålla mer tillförlitliga funktioner för parsning och reparation.

**7\. Slutsats:**

Rapporten har undersökt utmaningarna med att pålitligt extrahera strukturerad JSON-data och noggrant klassificera vegansk status från livsmedelsingredienslistor med hjälp av LLM, särskilt Gemini API. Genom analys av olika strategier och bästa praxis har ett antal rekommendationer framkommit för att förbättra tillförlitligheten och noggrannheten i denna process.

För att säkerställa tillförlitlig JSON-utdata är det avgörande att använda avancerade promptkonstruktionstekniker, inklusive tydliga instruktioner, definition av JSON-schemat i prompten och användning av few-shot prompting med relevanta exempel. Dessutom kan justering av Gemini API-parametrar som response\_mime\_type och finjustering av temperature, top\_p och top\_k mot mer deterministiska värden bidra till ökad konsekvens. Ett särskilt lovande tillvägagångssätt är att utnyttja Gemini API:s funktioner för funktionsanrop eller verktygsanvändning, vilket ger ett mer garanterat sätt att erhålla strukturerad utdata som följer ett definierat schema.

När det gäller att förbättra noggrannheten i vegansk statusklassificering är en kombination av riktad promptkonstruktion och strategisk integrering av interna ingrediensdatabaser (eller ett RAG-system) nödvändig. Att tillhandahålla relevanta delmängder av databasen eller använda few-shot prompting med korrekta klassificeringar kan vägleda LLM mer effektivt. Dessutom kan alternativa arbetsflödesdesigner, som en tvåstegsmetod som separerar OCR och klassificering, erbjuda ökad kontroll och potentiellt högre noggrannhet, särskilt om klassificeringssteget implementeras med regelbaserad logik och direkt databasuppslagning.

Slutligen är robust felhantering på klientsidan avgörande för att hantera inkonsekvenser i LLM-svar. Att implementera try-except-block, använda regex som en förbättrad fallback, identifiera JSON-gränser, utnyttja bibliotek för JSON-reparation, överväga LLM-självkorrigering och validera utdata mot ett definierat schema är viktiga steg för att säkerställa en motståndskraftig pipeline.

Det är viktigt att betona att iterativ experimentering och utvärdering är nyckeln till att finjustera det valda tillvägagångssättet och uppnå önskad nivå av tillförlitlighet och noggrannhet. Genom att kontinuerligt övervaka prestanda och anpassa strategierna efter behov kan en effektiv och tillförlitlig pipeline för analys av livsmedelsingredienser uppnås, vilket leder till förbättrad effektivitet och noggrannhet.