# Steg 18: Övervakning och loggning

## Mål och syfte
Implementera ett omfattande system för övervakning, loggning och analys av Gemini API-användning i produktionsmiljön. Detta är avgörande för att säkerställa prestanda, upptäcka problem tidigt, optimera kostnader och förbättra analysresultaten över tid genom att samla data om användningsmönster och resultatkvalitet.

## Förutsättningar
- Gemini-implementationen är driftsatt i produktion
- Tillgång till ett loggningsverktyg (t.ex. Winston, Pino)
- Tillgång till en monitoreringstjänst (t.ex. Datadog, Prometheus, eller New Relic)
- Behörighet att konfigurera larm och varningar
- Tillgång till produktionsmiljöns servrar och databaser

## Detaljerade instruktioner

### 1. Implementera strukturerad loggning för Gemini API-anrop

Skapa ett omfattande loggningssystem som fångar alla relevanta detaljer för API-anrop:

```typescript
// src/utils/aiLogger.ts
import winston from 'winston';
import { v4 as uuidv4 } from 'uuid';

// Skapa separat loggar för AI-anrop
const aiLogger = winston.createLogger({
  level: process.env.AI_LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  defaultMeta: { service: 'koalens-ai-service' },
  transports: [
    new winston.transports.File({ filename: 'logs/ai-error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/ai-requests.log', level: 'info' }),
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    })
  ]
});

// Skapa en strukturerad loggningsmetod för API-anrop
export const logAIRequest = (data: {
  requestId: string;
  provider: string;
  model: string;
  promptType: string;
  inputTokens: number;
  mediaType?: string;
  mediaSize?: number;
  userId?: string;
  timing: {
    startTime: number;
  };
}) => {
  aiLogger.info('AI Request', data);
  return data;
};

// Skapa en strukturerad loggningsmetod för API-svar
export const logAIResponse = (data: {
  requestId: string;
  provider: string;
  model: string;
  promptType: string;
  outputTokens: number;
  totalTokens: number;
  duration: number;
  status: 'success' | 'error';
  errorType?: string;
  cost?: number;
  isVegan?: boolean | null;
  confidence?: number;
  userId?: string;
}) => {
  aiLogger.info('AI Response', data);
  return data;
};

// Hjälpfunktion för att skapa en unik request ID
export const generateAIRequestId = () => {
  return uuidv4();
};

export default {
  logAIRequest,
  logAIResponse,
  generateAIRequestId
};
```

### 2. Uppdatera Gemini-tjänsten för att använda den strukturerade loggningen

Integrera loggningen i Gemini-servicen:

```typescript
// src/services/geminiService.ts - uppdatera generateContent-metoden
async generateContent(prompt: string, userId?: string): Promise<any> {
  const requestId = generateAIRequestId();
  const startTime = Date.now();
  const promptTokenCount = await this.countTokens(prompt);
  
  // Logga förfrågan
  logAIRequest({
    requestId,
    provider: 'gemini',
    model: this.modelName,
    promptType: 'text',
    inputTokens: promptTokenCount,
    userId,
    timing: {
      startTime
    }
  });
  
  try {
    const model = this.genAI.getGenerativeModel({ model: this.modelName });
    
    // Konfigurationer för modellen...
    
    // Utför API-anrop
    const result = await model.generateContent({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      safetySettings,
      generationConfig,
    });
    
    const response = result.response;
    const text = response.text();
    const endTime = Date.now();
    const duration = endTime - startTime;
    
    // Estimera outputTokens
    const outputTokenCount = Math.ceil(text.length / 4);
    
    // Estimera kostnad baserat på pricing information
    const cost = this.calculateCost(promptTokenCount, outputTokenCount);
    
    // Logga svar
    logAIResponse({
      requestId,
      provider: 'gemini',
      model: this.modelName,
      promptType: 'text',
      outputTokens: outputTokenCount,
      totalTokens: promptTokenCount + outputTokenCount,
      duration,
      status: 'success',
      cost,
      userId
    });
    
    return text;
  } catch (error: any) {
    const endTime = Date.now();
    const duration = endTime - startTime;
    
    // Logga fel
    logAIResponse({
      requestId,
      provider: 'gemini',
      model: this.modelName,
      promptType: 'text',
      outputTokens: 0,
      totalTokens: promptTokenCount,
      duration,
      status: 'error',
      errorType: error.message,
      userId
    });
    
    logger.error('Gemini API error', { error: error.message, stack: error.stack });
    throw new Error(`Gemini API error: ${error.message}`);
  }
}

// Lägg till hjälpmetod för att beräkna kostnader
private calculateCost(inputTokens: number, outputTokens: number): number {
  // Gemini 2.5 Pro-priser (uppdatera enligt aktuella priser)
  const inputTokenPrice = 0.00000350; // $0.0035 per 1000 tokens
  const outputTokenPrice = 0.00001050; // $0.0105 per 1000 tokens
  
  const inputCost = (inputTokens / 1000) * inputTokenPrice;
  const outputCost = (outputTokens / 1000) * outputTokenPrice;
  
  return inputCost + outputCost;
}
```

### 3. Implementera loggrotation och komprimering

Konfigurera loggrotation för att hantera loggfiler effektivt:

```javascript
// src/config/logConfig.js
const { createLogger, format, transports } = require('winston');
require('winston-daily-rotate-file');

const transport = new transports.DailyRotateFile({
  filename: 'logs/ai-requests-%DATE%.log',
  datePattern: 'YYYY-MM-DD',
  zippedArchive: true,
  maxSize: '20m',
  maxFiles: '14d'
});

const errorTransport = new transports.DailyRotateFile({
  filename: 'logs/ai-errors-%DATE%.log',
  datePattern: 'YYYY-MM-DD',
  zippedArchive: true,
  maxSize: '20m',
  maxFiles: '30d',
  level: 'error'
});

// Skapa loggern
const logger = createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: format.combine(
    format.timestamp(),
    format.json()
  ),
  transports: [
    transport,
    errorTransport,
    new transports.Console({
      format: format.combine(
        format.colorize(),
        format.simple()
      )
    })
  ]
});

module.exports = logger;
```

### 4. Sätt upp en databas för att spara analysresultat för långsiktig analys

Skapa ett databasschema för att spara analysdata:

```sql
-- Spara i en migrations-fil, t.ex. migrations/20250326_create_ai_analytics.sql
CREATE TABLE ai_analytics (
  id SERIAL PRIMARY KEY,
  request_id UUID NOT NULL,
  provider VARCHAR(50) NOT NULL,
  model VARCHAR(50) NOT NULL,
  prompt_type VARCHAR(50) NOT NULL,
  input_tokens INTEGER NOT NULL,
  output_tokens INTEGER NOT NULL,
  duration_ms INTEGER NOT NULL,
  status VARCHAR(20) NOT NULL,
  error_type VARCHAR(255),
  cost DECIMAL(10, 6),
  is_vegan BOOLEAN,
  confidence DECIMAL(5, 4),
  user_id UUID,
  timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  raw_request JSONB,
  raw_response JSONB
);

-- Skapa index för snabbare sökningar
CREATE INDEX ai_analytics_user_id_idx ON ai_analytics(user_id);
CREATE INDEX ai_analytics_timestamp_idx ON ai_analytics(timestamp);
CREATE INDEX ai_analytics_provider_model_idx ON ai_analytics(provider, model);
```

Implementera en service för att spara till databasen:

```typescript
// src/services/analyticsService.ts
import { Pool } from 'pg';
import logger from '../utils/logger';

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
});

interface AIAnalyticsData {
  requestId: string;
  provider: string;
  model: string;
  promptType: string;
  inputTokens: number;
  outputTokens: number;
  durationMs: number;
  status: string;
  errorType?: string;
  cost?: number;
  isVegan?: boolean | null;
  confidence?: number;
  userId?: string;
  rawRequest?: any;
  rawResponse?: any;
}

export class AnalyticsService {
  async saveAIAnalytics(data: AIAnalyticsData): Promise<void> {
    try {
      await pool.query(
        `INSERT INTO ai_analytics (
          request_id, provider, model, prompt_type, input_tokens, 
          output_tokens, duration_ms, status, error_type, cost, 
          is_vegan, confidence, user_id, raw_request, raw_response
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)`,
        [
          data.requestId, data.provider, data.model, data.promptType, data.inputTokens,
          data.outputTokens, data.durationMs, data.status, data.errorType, data.cost,
          data.isVegan, data.confidence, data.userId, 
          data.rawRequest ? JSON.stringify(data.rawRequest) : null,
          data.rawResponse ? JSON.stringify(data.rawResponse) : null
        ]
      );
    } catch (error: any) {
      logger.error('Failed to save AI analytics', { 
        error: error.message, 
        data: { ...data, rawRequest: undefined, rawResponse: undefined } 
      });
    }
  }
  
  async getAIAnalyticsSummary(days: number = 30): Promise<any> {
    try {
      const result = await pool.query(`
        SELECT 
          provider, 
          model, 
          COUNT(*) as total_requests,
          SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as successful_requests,
          SUM(CASE WHEN status = 'error' THEN 1 ELSE 0 END) as failed_requests,
          AVG(duration_ms) as avg_duration_ms,
          SUM(input_tokens) as total_input_tokens,
          SUM(output_tokens) as total_output_tokens,
          SUM(cost) as total_cost
        FROM ai_analytics
        WHERE timestamp > NOW() - INTERVAL '${days} days'
        GROUP BY provider, model
        ORDER BY total_requests DESC
      `);
      
      return result.rows;
    } catch (error: any) {
      logger.error('Failed to get AI analytics summary', { error: error.message });
      return [];
    }
  }
  
  async getVeganAnalysisAccuracy(days: number = 30): Promise<any> {
    try {
      const result = await pool.query(`
        SELECT 
          provider,
          COUNT(*) as total_analyses,
          SUM(CASE WHEN is_vegan IS NOT NULL THEN 1 ELSE 0 END) as determined_analyses,
          SUM(CASE WHEN is_vegan IS NULL THEN 1 ELSE 0 END) as undetermined_analyses,
          AVG(confidence) as avg_confidence
        FROM ai_analytics
        WHERE 
          timestamp > NOW() - INTERVAL '${days} days'
          AND prompt_type IN ('ingredient_analysis', 'image_analysis', 'video_analysis')
        GROUP BY provider
        ORDER BY total_analyses DESC
      `);
      
      return result.rows;
    } catch (error: any) {
      logger.error('Failed to get vegan analysis accuracy', { error: error.message });
      return [];
    }
  }
}

export default new AnalyticsService();
```

### 5. Sätt upp realtidsmonitorering med Prometheus och Grafana

Konfigurera Prometheus för att samla metrics och Grafana för visualisering:

```typescript
// src/middleware/prometheusMiddleware.ts
import express from 'express';
import promClient from 'prom-client';

// Skapa register för Prometheus metrics
const register = new promClient.Registry();
promClient.collectDefaultMetrics({ register });

// Skapa custom metrics
const httpRequestDurationMicroseconds = new promClient.Histogram({
  name: 'http_request_duration_ms',
  help: 'Duration of HTTP requests in ms',
  labelNames: ['method', 'route', 'status'],
  buckets: [5, 10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000]
});

const aiRequestDurationSeconds = new promClient.Histogram({
  name: 'ai_request_duration_seconds',
  help: 'Duration of AI requests in seconds',
  labelNames: ['provider', 'model', 'status'],
  buckets: [0.1, 0.5, 1, 2, 5, 10, 20, 30, 60]
});

const aiRequestTokensTotal = new promClient.Counter({
  name: 'ai_request_tokens_total',
  help: 'Total number of tokens processed by AI requests',
  labelNames: ['provider', 'model', 'type']
});

const aiRequestErrorsTotal = new promClient.Counter({
  name: 'ai_request_errors_total',
  help: 'Total number of AI request errors',
  labelNames: ['provider', 'model', 'error_type']
});

// Registrera custom metrics
register.registerMetric(httpRequestDurationMicroseconds);
register.registerMetric(aiRequestDurationSeconds);
register.registerMetric(aiRequestTokensTotal);
register.registerMetric(aiRequestErrorsTotal);

// Exportera metrics som kan användas i koden
export const metrics = {
  httpRequestDurationMicroseconds,
  aiRequestDurationSeconds,
  aiRequestTokensTotal,
  aiRequestErrorsTotal
};

// Middleware för att mäta HTTP request duration
export const httpMetricsMiddleware = (
  req: express.Request, 
  res: express.Response, 
  next: express.NextFunction
) => {
  const start = Date.now();
  
  // Skapa en end-event-handler
  res.on('finish', () => {
    const duration = Date.now() - start;
    const path = req.route ? req.route.path : req.path;
    
    // Observera metrics
    httpRequestDurationMicroseconds
      .labels(req.method, path, res.statusCode.toString())
      .observe(duration);
  });
  
  next();
};

// Middleware för att exponera Prometheus metrics endpoint
export const prometheusMiddleware = (app: express.Application) => {
  app.get('/metrics', async (req, res) => {
    res.set('Content-Type', register.contentType);
    res.end(await register.metrics());
  });
  
  // Applicera HTTP metrics middleware på alla routes
  app.use(httpMetricsMiddleware);
};
```

Uppdatera Gemini-service för att inkludera Prometheus metrics:

```typescript
// src/services/geminiService.ts - uppdatera generateContent-metoden
import { metrics } from '../middleware/prometheusMiddleware';

async generateContent(prompt: string, userId?: string): Promise<any> {
  const requestId = generateAIRequestId();
  const startTime = Date.now();
  const promptTokenCount = await this.countTokens(prompt);
  
  // Logga förfrågan...
  
  try {
    // Utför API-anrop...
    
    const response = result.response;
    const text = response.text();
    const endTime = Date.now();
    const duration = endTime - startTime;
    const durationInSeconds = duration / 1000;
    
    // Registrera Prometheus metrics
    metrics.aiRequestDurationSeconds
      .labels('gemini', this.modelName, 'success')
      .observe(durationInSeconds);
    
    metrics.aiRequestTokensTotal
      .labels('gemini', this.modelName, 'input')
      .inc(promptTokenCount);
    
    metrics.aiRequestTokensTotal
      .labels('gemini', this.modelName, 'output')
      .inc(outputTokenCount);
    
    // Logga svar...
    
    return text;
  } catch (error: any) {
    // Registrera Prometheus metrics för fel
    metrics.aiRequestErrorsTotal
      .labels('gemini', this.modelName, error.message.substring(0, 30))
      .inc();
    
    // Logga fel...
    
    throw new Error(`Gemini API error: ${error.message}`);
  }
}
```

### 6. Sätt upp dashboards i Grafana

Skapa Grafana-dashboards för att visualisera prestanda och användning:

```json
// grafana-dashboards/ai-performance.json
{
  "dashboard": {
    "id": null,
    "title": "KoaLens AI Performance",
    "tags": ["koalens", "ai", "gemini"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "AI Request Duration",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "rate(ai_request_duration_seconds_sum[5m]) / rate(ai_request_duration_seconds_count[5m])",
            "legendFormat": "{{provider}} - {{model}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "AI Tokens Processed",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "sum(rate(ai_request_tokens_total[5m])) by (provider, model, type)",
            "legendFormat": "{{provider}} - {{model}} - {{type}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "AI Request Errors",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "sum(rate(ai_request_errors_total[5m])) by (provider, model)",
            "legendFormat": "{{provider}} - {{model}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "HTTP Endpoints Performance",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "rate(http_request_duration_ms_sum[5m]) / rate(http_request_duration_ms_count[5m])",
            "legendFormat": "{{method}} {{route}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      }
    ]
  }
}
```

### 7. Konfigurera larm för kritiska problem

Skapa larm i Prometheus Alertmanager för att reagera på problem:

```yaml
# alertmanager-config.yml
groups:
- name: koalens_alerts
  rules:
  - alert: GeminiAPIErrors
    expr: sum(increase(ai_request_errors_total{provider="gemini"}[5m])) > 10
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Högt antal Gemini API-fel"
      description: "Det har inträffat {{ $value }} Gemini API-fel under de senaste 5 minuterna."

  - alert: HighGeminiLatency
    expr: rate(ai_request_duration_seconds_sum{provider="gemini"}[5m]) / rate(ai_request_duration_seconds_count{provider="gemini"}[5m]) > 5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Hög latens för Gemini API"
      description: "Genomsnittlig Gemini API-svarstid är {{ $value }} sekunder."

  - alert: HighAPIUsage
    expr: sum(increase(ai_request_tokens_total{provider="gemini"}[1h])) > 1000000
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Hög API-användning"
      description: "Över 1 miljon tokens har använts under den senaste timmen."

  - alert: HighErrorRate
    expr: sum(rate(ai_request_errors_total[5m])) / sum(rate(ai_request_duration_seconds_count[5m])) > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Hög felfrekvens för AI-förfrågningar"
      description: "Mer än 5% av alla AI-förfrågningar misslyckas."
```

### 8. Implementera en health check endpoint

Lägg till en health check endpoint som inkluderar Gemini API-status:

```typescript
// src/routes/healthRoutes.ts
import express from 'express';
import { GeminiService } from '../services/geminiService';

const router = express.Router();
const geminiService = new GeminiService();

// Grundläggande health check
router.get('/health', async (_, res) => {
  res.json({ status: 'ok' });
});

// Detaljerad health check för AI-services
router.get('/health/ai', async (_, res) => {
  try {
    // Testa Gemini API med en enkel prompt
    const result = await geminiService.generateContent('Hej, detta är en hälsokontroll.');
    
    res.json({
      status: 'ok',
      gemini: {
        status: 'online',
        responseTime: Date.now() - (res.locals.requestStartTime || Date.now())
      }
    });
  } catch (error: any) {
    res.status(500).json({
      status: 'error',
      gemini: {
        status: 'offline',
        error: error.message
      }
    });
  }
});

export default router;
```

### 9. Implementera ett system för feedback-loggning från användare

Skapa en endpoint för att samla användarfeedback:

```typescript
// src/routes/feedbackRoutes.ts
import express from 'express';
import { Pool } from 'pg';
import logger from '../utils/logger';

const router = express.Router();
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
});

router.post('/feedback', async (req, res) => {
  try {
    const { 
      requestId, 
      accuracy, 
      quality, 
      userId, 
      isCorrect, 
      comment 
    } = req.body;
    
    if (!requestId) {
      return res.status(400).json({ 
        error: 'REQUEST_ID_MISSING', 
        message: 'Request ID är obligatoriskt' 
      });
    }
    
    // Spara feedback i databasen
    await pool.query(
      `INSERT INTO user_feedback (
        request_id, accuracy_rating, quality_rating, 
        user_id, is_correct, comment, timestamp
      ) VALUES ($1, $2, $3, $4, $5, $6, NOW())`,
      [requestId, accuracy, quality, userId, isCorrect, comment]
    );
    
    // Logga feedback för analys
    logger.info('User feedback received', {
      requestId,
      accuracy,
      quality,
      userId,
      isCorrect
    });
    
    return res.json({ status: 'ok', message: 'Feedback mottagen' });
  } catch (error: any) {
    logger.error('Error saving feedback', { error: error.message });
    
    return res.status(500).json({
      error: 'FEEDBACK_ERROR',
      message: `Ett fel uppstod: ${error.message}`
    });
  }
});

export default router;
```

### 10. Konfigurera dagliga rapporter och sammanfattningar

Skapa ett cron-jobb för att skicka dagliga sammanfattningar:

```typescript
// src/cron/dailyReports.ts
import cron from 'node-cron';
import nodemailer from 'nodemailer';
import analyticsService from '../services/analyticsService';
import logger from '../utils/logger';

// Konfigurera e-post
const transporter = nodemailer.createTransport({
  host: process.env.SMTP_HOST,
  port: parseInt(process.env.SMTP_PORT || '587'),
  secure: process.env.SMTP_SECURE === 'true',
  auth: {
    user: process.env.SMTP_USER,
    pass: process.env.SMTP_PASS
  }
});

// Skapa funktion för att generera och skicka daglig rapport
async function generateDailyReport() {
  try {
    // Hämta data för det senaste dygnet
    const aiSummary = await analyticsService.getAIAnalyticsSummary(1);
    const veganAccuracy = await analyticsService.getVeganAnalysisAccuracy(1);
    
    // Skapa HTML-innehåll
    const html = `
      <h1>KoaLens Daglig AI-rapport</h1>
      <p>Här är en sammanfattning av AI-användningen för det senaste dygnet.</p>
      
      <h2>AI-användning per provider/modell</h2>
      <table border="1" cellpadding="5">
        <tr>
          <th>Provider</th>
          <th>Modell</th>
          <th>Totalt</th>
          <th>Lyckade</th>
          <th>Misslyckade</th>
          <th>Svarstid (ms)</th>
          <th>Input tokens</th>
          <th>Output tokens</th>
          <th>Kostnad</th>
        </tr>
        ${aiSummary.map(row => `
          <tr>
            <td>${row.provider}</td>
            <td>${row.model}</td>
            <td>${row.total_requests}</td>
            <td>${row.successful_requests}</td>
            <td>${row.failed_requests}</td>
            <td>${Math.round(row.avg_duration_ms)}</td>
            <td>${row.total_input_tokens}</td>
            <td>${row.total_output_tokens}</td>
            <td>$${row.total_cost.toFixed(2)}</td>
          </tr>
        `).join('')}
      </table>
      
      <h2>Vegansk analysaccuracy</h2>
      <table border="1" cellpadding="5">
        <tr>
          <th>Provider</th>
          <th>Totalt</th>
          <th>Bedömda</th>
          <th>Obesvarade</th>
          <th>Genomsnittlig confidence</th>
        </tr>
        ${veganAccuracy.map(row => `
          <tr>
            <td>${row.provider}</td>
            <td>${row.total_analyses}</td>
            <td>${row.determined_analyses}</td>
            <td>${row.undetermined_analyses}</td>
            <td>${(row.avg_confidence * 100).toFixed(1)}%</td>
          </tr>
        `).join('')}
      </table>
    `;
    
    // Skicka rapport
    await transporter.sendMail({
      from: `"KoaLens AI Monitor" <${process.env.SMTP_USER}>`,
      to: process.env.REPORT_RECIPIENTS,
      subject: `KoaLens AI-rapport ${new Date().toISOString().split('T')[0]}`,
      html
    });
    
    logger.info('Daily report sent successfully');
  } catch (error: any) {
    logger.error('Failed to generate and send daily report', { error: error.message });
  }
}

// Schemalägg cron-jobbet att köra dagligen kl 08:00
export function scheduleDailyReports() {
  cron.schedule('0 8 * * *', generateDailyReport);
  logger.info('Daily reports scheduled');
}
```

## Verifiering

För att verifiera att övervakning och loggning fungerar korrekt:

1. Testa loggningssystemet genom att göra några API-anrop och kontrollera loggarna:
```bash
# Granska real-time loggar
tail -f logs/ai-requests.log

# Sök efter specifika händelser
grep "error" logs/ai-errors.log

# Kontrollera antal loggade anrop
wc -l logs/ai-requests.log
```

2. Validera Prometheus metrics:
```bash
# Kontrollera att metrics-endpointen returnerar data
curl http://localhost:3000/metrics | grep ai_request
```

3. Kontrollera att data sparas i databasen:
```sql
-- Kör SQL-fråga för att verifiera att data sparas
SELECT COUNT(*) FROM ai_analytics WHERE timestamp > NOW() - INTERVAL '1 day';

-- Kontrollera att kostnadsinformation sparas korrekt
SELECT SUM(cost) FROM ai_analytics WHERE timestamp > NOW() - INTERVAL '1 day';
```

4. Testa health check-endpointen:
```bash
curl http://localhost:3000/health/ai
```

## Felsökning

### Problem: Loggar skapas inte
**Lösning**: Kontrollera rättigheter för loggdirectoryn:
```bash
# Skapa logs-directoryn om den inte existerar
mkdir -p logs

# Sätt rätt behörigheter
chmod -R 755 logs

# Kontrollera att processen har skrivrättigheter
touch logs/test.log && rm logs/test.log
```

### Problem: Prometheus metrics fungerar inte
**Lösning**: Verifiera att Prometheus-middleware är korrekt konfigurerad:
```typescript
// Lägg till i app.ts
import { prometheusMiddleware } from './middleware/prometheusMiddleware';

// Konfigurera Express-appen
const app = express();

// Applicera middleware före routedefinitioner
prometheusMiddleware(app);
```

### Problem: Kostnadsinformation är felaktig
**Lösning**: Uppdatera prismodellen i beräkningsfunktionen:
```typescript
// Uppdatera calculateCost-metoden med aktuella priser
private calculateCost(inputTokens: number, outputTokens: number): number {
  // Aktuella Gemini 2.5 Pro-priser
  const inputTokenPrice = 0.00000350; // $0.0035 per 1000 tokens
  const outputTokenPrice = 0.00001050; // $0.0105 per 1000 tokens
  
  console.log('Calculating cost with prices:', { inputTokenPrice, outputTokenPrice });
  
  const inputCost = (inputTokens / 1000) * inputTokenPrice;
  const outputCost = (outputTokens / 1000) * outputTokenPrice;
  
  return inputCost + outputCost;
}
```

### Problem: E-postrapporter levereras inte
**Lösning**: Verifiera SMTP-konfigurationen:
```javascript
// Testa SMTP-anslutning
const testConnection = async () => {
  try {
    const info = await transporter.verify();
    console.log('SMTP connection successful:', info);
  } catch (error) {
    console.error('SMTP connection failed:', error);
  }
};

testConnection();
```

## Nästa steg

Nu när du har implementerat ett robust övervaknings- och loggningssystem, är du redo att gå vidare till det sista steget: "Iterativ förbättring" där du kommer att arbeta med att kontinuerligt förbättra Gemini-implementationen baserat på de data du samlar in.

## Referenser
- [Prometheus dokumentation](https://prometheus.io/docs/introduction/overview/)
- [Grafana dokumentation](https://grafana.com/docs/grafana/latest/)
- [Winston logging library](https://github.com/winstonjs/winston)
- [Node-cron dokumentation](https://github.com/node-cron/node-cron)
- [Google Gemini API-priser](https://ai.google.dev/pricing)
- [Datadog monitoring guide](https://docs.datadoghq.com/guides/)
